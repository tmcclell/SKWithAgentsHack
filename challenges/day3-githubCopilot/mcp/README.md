# Day 4: GitHub Copilot & MCP Integration

## üéØ Learning Objectives

By the end of Day 4, you will:
- Install and configure GitHub Copilot in Visual Studio Professional
- Understand GitHub Copilot key concepts including agent mode
- Learn Model Context Protocol (MCP) key concepts and architecture
- Set up Visual Studio Professional to use Azure and GitHub MCP
- Integrate MCP with development workflows for enhanced productivity

## üìö Key Concepts

### GitHub Copilot Overview
- **AI-Powered Code Completion**: Intelligent code suggestions and completions
  - Context-aware code generation based on comments and existing code
  - Support for multiple programming languages and frameworks
  - Integration with development workflows and IDEs
  - Real-time code analysis and suggestions

- **Agent Mode**: Advanced AI assistance capabilities
  - Conversational AI for complex development tasks
  - Code explanation and refactoring suggestions
  - Automated documentation generation
  - Code review and quality improvement recommendations

### Model Context Protocol (MCP) Key Concepts
- **MCP Architecture**: Standardized protocol for AI model communication
  - Client-server architecture for AI model integration
  - Standardized message formats and communication patterns
  - Plugin-based extensibility for custom functionality
  - Cross-platform compatibility and interoperability

- **MCP in Development Context**: Enhancing development workflows
  - Integration with development tools and environments
  - Custom model endpoints and specialized AI capabilities
  - Workflow automation and intelligent task orchestration
  - Enhanced code understanding and generation

## üèóÔ∏è Tutorial Walkthroughs

### Walkthrough 4.1: Install GitHub Copilot in Visual Studio Professional (30 minutes)

**Summary**: Install and configure GitHub Copilot in Visual Studio Professional, enabling AI-powered code completion and development assistance. This walkthrough covers installation, authentication, and basic usage patterns.

**Prerequisites**: 
- Visual Studio Professional 2022 (version 17.0 or later)
- GitHub account with Copilot subscription
- Active Azure subscription (for enterprise features)

**Step-by-Step Guide**:

**Step 1: Install GitHub Copilot Extension (10 minutes)**
1. Open Visual Studio Professional 2022
2. Navigate to **Extensions** ‚Üí **Manage Extensions**
3. Search for "GitHub Copilot" in the Online tab
4. Click **Download** on "GitHub Copilot" by GitHub
5. Close Visual Studio to allow installation to complete
6. Reopen Visual Studio - the extension should be installed

**Step 2: Authenticate with GitHub (10 minutes)**
1. In Visual Studio, go to **Tools** ‚Üí **Options**
2. Navigate to **GitHub Copilot** in the left panel
3. Click **Enable GitHub Copilot**
4. Click **Sign in to GitHub** - this will open your browser
5. Authenticate with your GitHub account credentials
6. Authorize the Visual Studio application
7. Return to Visual Studio and verify the connection status shows "Connected"

**Step 3: Configure Copilot Settings (10 minutes)**
1. In **Tools** ‚Üí **Options** ‚Üí **GitHub Copilot**, configure:
   - **Enable GitHub Copilot**: ‚úì Checked
   - **Enable for all file types**: ‚úì Recommended
   - **Show suggestions**: Automatic (recommended)
   - **Suggestion display mode**: Inline (recommended)

2. Test the installation:
   - Create a new C# console application
   - Type a comment: `// Function to calculate migration cost`
   - Press Enter and start typing `public decimal` - Copilot should suggest completions
   - Press Tab to accept suggestions

3. Verify Copilot is working:
   - Look for the GitHub Copilot icon in the status bar
   - Status should show "Ready" or suggestion count
   - Try typing common coding patterns to see suggestions

**Documentation Reference**: [GitHub Copilot in Visual Studio](https://learn.microsoft.com/en-us/visualstudio/ide/visual-studio-github-copilot-install-and-states?view=vs-2022)

### Walkthrough 4.2: GitHub Copilot Key Concepts and Agent Mode (45 minutes)

**Summary**: Explore GitHub Copilot's advanced features including agent mode, conversational AI capabilities, and integration with development workflows. Learn how to leverage Copilot for complex development tasks beyond code completion.

**Prerequisites**: 
- Completed Walkthrough 4.1 (GitHub Copilot installation)
- Basic understanding of Visual Studio IDE
- Sample C# project or migration project from previous days

**Step-by-Step Guide**:

**Step 1: Understand Core Copilot Features (15 minutes)**
1. **Code Completion in Action**:
   - Create a new class: `public class MigrationAnalyzer`
   - Add comment: `// Analyze infrastructure requirements`
   - Type method signature: `public async Task<` - observe suggestions
   - Accept completions with Tab, reject with Escape

2. **Context-Aware Suggestions**:
   - Add using statements for Azure SDKs
   - Type Azure-specific code patterns
   - Notice how Copilot adapts to your project context
   - Example: Start typing `var client = new` and see Azure suggestions

3. **Multi-line Code Generation**:
   - Type comment: `// Method to migrate SQL database to Azure SQL`
   - Press Enter and let Copilot generate the entire method
   - Review the generated code structure and logic

**Step 2: Explore Agent Mode (15 minutes)**
1. **Access Copilot Chat**:
   - Right-click in code editor ‚Üí **Ask Copilot**
   - Or use **View** ‚Üí **GitHub Copilot Chat**
   - The chat panel opens on the right side

2. **Conversational Code Assistance**:
   - Ask: "Explain this code" (select a code block first)
   - Ask: "How can I improve this function's performance?"
   - Ask: "Generate unit tests for this class"
   - Ask: "Add error handling to this method"

3. **Complex Development Tasks**:
   - Ask: "Create a migration plan class with phases and tasks"
   - Ask: "Generate a configuration class for Azure services"
   - Ask: "Add logging and monitoring to this migration tool"

**Step 3: Advanced Agent Mode Capabilities (15 minutes)**
1. **Code Refactoring Assistance**:
   - Select a large method
   - Ask Copilot: "Break this method into smaller, more focused methods"
   - Review and apply the suggestions

2. **Documentation Generation**:
   - Select a class or method
   - Ask: "Generate XML documentation for this code"
   - Ask: "Create a README section explaining this functionality"

3. **Architecture and Design Guidance**:
   - Ask: "What design patterns would improve this migration tool?"
   - Ask: "How should I structure this Azure migration application?"
   - Ask: "What are the best practices for error handling in Azure SDK calls?"

4. **Testing and Quality Assurance**:
   - Ask: "Generate comprehensive unit tests for this migration class"
   - Ask: "What edge cases should I test for this Azure migration function?"
   - Ask: "Create integration tests for this Azure service client"

**Documentation Reference**: [GitHub Copilot Agent Mode](https://learn.microsoft.com/en-us/visualstudio/ide/visual-studio-github-copilot-extension?view=vs-2022)

### Walkthrough 4.3: Model Context Protocol (MCP) Key Concepts (45 minutes)

**Summary**: Understand the Model Context Protocol architecture, its role in AI development workflows, and how it enables standardized communication between AI models and development tools.

**Prerequisites**: 
- Understanding of AI development concepts
- Basic knowledge of API design and protocols
- Familiarity with development tool integration

**Step-by-Step Guide**:

**Step 1: MCP Architecture Overview (15 minutes)**
1. **Core Components**:
   - **MCP Client**: Development tool or application requesting AI services
   - **MCP Server**: AI model endpoint providing services
   - **Protocol Layer**: Standardized message format and communication rules
   - **Transport Layer**: HTTP, WebSocket, or other communication channels

2. **Key Concepts**:
   - **Resources**: Data sources and information available to AI models
   - **Tools**: Functions and capabilities that AI models can execute
   - **Prompts**: Standardized templates for AI model interactions
   - **Sampling**: Methods for AI model inference and response generation

3. **Protocol Benefits**:
   - **Standardization**: Consistent interface across different AI models
   - **Extensibility**: Plugin-based architecture for custom functionality
   - **Interoperability**: Cross-platform and cross-tool compatibility
   - **Composability**: Ability to combine multiple AI capabilities

**Step 2: MCP Message Flow and Communication (15 minutes)**
1. **Request-Response Pattern**:
   ```json
   {
     "jsonrpc": "2.0",
     "id": "1",
     "method": "resources/read",
     "params": {
       "uri": "file:///path/to/migration-plan.md"
     }
   }
   ```

2. **Resource Management**:
   - **Resource Discovery**: Finding available data sources
   - **Resource Access**: Reading and processing information
   - **Resource Updates**: Handling changes and notifications
   - **Resource Permissions**: Security and access control

3. **Tool Execution**:
   - **Tool Discovery**: Finding available AI capabilities
   - **Tool Invocation**: Executing AI functions with parameters
   - **Tool Results**: Processing and handling AI responses
   - **Tool Composition**: Chaining multiple AI operations

**Step 3: MCP Integration Patterns (15 minutes)**
1. **Development Tool Integration**:
   - **IDE Extensions**: Integrating MCP into development environments
   - **CLI Tools**: Command-line interfaces for MCP services
   - **Build Systems**: Incorporating AI capabilities into build processes
   - **Testing Frameworks**: AI-powered testing and validation

2. **Common Use Cases**:
   - **Code Generation**: AI-powered code creation and completion
   - **Documentation**: Automated documentation generation and updates
   - **Code Review**: AI-assisted code quality analysis
   - **Migration Planning**: AI-powered migration strategy development

3. **Best Practices**:
   - **Error Handling**: Robust error handling and recovery
   - **Performance**: Efficient resource usage and response times
   - **Security**: Secure communication and data handling
   - **Monitoring**: Observability and debugging capabilities

**Documentation Reference**: [Model Context Protocol Specification](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol)

### Walkthrough 4.4: Setup Visual Studio Professional for Azure and GitHub MCP (60 minutes)

**Summary**: Configure Visual Studio Professional to work with Azure services and GitHub MCP, enabling enhanced development workflows with AI-powered assistance for Azure development and migration projects.

**Prerequisites**: 
- Visual Studio Professional 2022 with GitHub Copilot installed
- Azure subscription with contributor access
- GitHub account with MCP access (if available)
- Completed previous walkthroughs from Days 1-3

**Step-by-Step Guide**:

**Step 1: Configure Azure Integration (20 minutes)**
1. **Install Azure Development Workload**:
   - Open Visual Studio Installer
   - Click "Modify" for Visual Studio Professional
   - Select "Azure development" workload
   - Ensure these components are selected:
     - Azure SDK for .NET
     - Azure Data Lake and Stream Analytics Tools
     - Azure Service Fabric Tools
     - Azure PowerShell
   - Click "Modify" to install

2. **Configure Azure Authentication**:
   - In Visual Studio, go to **Tools** ‚Üí **Options**
   - Navigate to **Azure Service Authentication**
   - Click **Account Selection** ‚Üí **Add an account**
   - Sign in with your Azure credentials
   - Verify the account shows in the dropdown

3. **Test Azure Integration**:
   - Create new project: **File** ‚Üí **New** ‚Üí **Project**
   - Select "Azure Functions" template
   - Verify Azure resources appear in Server Explorer
   - Test deployment to Azure (optional)

**Step 2: Setup GitHub MCP Integration (20 minutes)**
1. **Install MCP Extension** (if available):
   - Navigate to **Extensions** ‚Üí **Manage Extensions**
   - Search for "Model Context Protocol" or "GitHub MCP"
   - Install available MCP-related extensions
   - Restart Visual Studio

2. **Configure MCP Settings**:
   - Go to **Tools** ‚Üí **Options**
   - Look for "Model Context Protocol" or "MCP" settings
   - Configure connection settings:
     - **MCP Server Endpoint**: Your MCP server URL
     - **Authentication**: GitHub token or Azure credentials
     - **Timeout Settings**: Appropriate for your network

3. **Create MCP Configuration File**:
   - In your project root, create `.mcpconfig.json`:
   ```json
   {
     "servers": {
       "github": {
         "command": "npx",
         "args": ["@modelcontextprotocol/server-github"],
         "env": {
           "GITHUB_PERSONAL_ACCESS_TOKEN": "your-token-here"
         }
       },
       "azure": {
         "command": "npx",
         "args": ["@modelcontextprotocol/server-azure"],
         "env": {
           "AZURE_SUBSCRIPTION_ID": "your-subscription-id",
           "AZURE_TENANT_ID": "your-tenant-id"
         }
       }
     }
   }
   ```

**Step 3: Configure Development Workflow Integration (20 minutes)**
1. **Project Template Setup**:
   - Create a new Azure Migration project
   - Add the following project structure:
   ```
   MigrationProject/
   ‚îú‚îÄ‚îÄ .mcpconfig.json
   ‚îú‚îÄ‚îÄ src/
   ‚îÇ   ‚îú‚îÄ‚îÄ MigrationTool/
   ‚îÇ   ‚îî‚îÄ‚îÄ MigrationTool.Tests/
   ‚îú‚îÄ‚îÄ docs/
   ‚îÇ   ‚îî‚îÄ‚îÄ migration-plan.md
   ‚îî‚îÄ‚îÄ scripts/
       ‚îî‚îÄ‚îÄ deploy-azure.ps1
   ```

2. **Configure Code Generation Workflow**:
   - Right-click on project ‚Üí **Properties**
   - Go to **Build Events**
   - Add pre-build event:
   ```bash
   echo "Initializing MCP for build..."
   npx @modelcontextprotocol/cli init
   ```

3. **Test MCP Integration**:
   - Open a C# file in your project
   - Try using Copilot with Azure-specific requests:
     - "Generate Azure Function for migration status"
     - "Create Azure Service Bus client code"
     - "Add Azure Key Vault configuration"
   - Verify responses include Azure-specific suggestions

**Step 4: Advanced MCP Usage and Workflow (Optional)**
1. **Custom MCP Tools**:
   - Create custom MCP tools for your migration workflow
   - Example: Migration assessment tool integration
   - Example: Azure cost calculator MCP server

2. **Monitoring and Debugging**:
   - Enable MCP logging in Visual Studio
   - Monitor MCP requests and responses
   - Debug MCP integration issues

3. **Team Collaboration**:
   - Share MCP configurations with team members
   - Create team-specific MCP resources
   - Establish MCP usage guidelines

**Documentation Reference**: [Visual Studio Azure Integration](https://learn.microsoft.com/en-us/visualstudio/azure/?view=vs-2022)

## üìù Deliverables

After completing Day 4 tutorial walkthroughs, you should have:

- [ ] **GitHub Copilot Installation**: Fully configured in Visual Studio Professional
- [ ] **Agent Mode Proficiency**: Understanding of conversational AI capabilities
- [ ] **MCP Knowledge**: Comprehensive understanding of Model Context Protocol
- [ ] **Development Environment**: Visual Studio configured for Azure and GitHub MCP
- [ ] **Workflow Integration**: AI-enhanced development workflow for migration projects

## üöÄ Next Steps

After completing Day 4 tutorials, you'll have a comprehensive AI-enhanced development environment ready for advanced migration projects and production deployments.

## üìö Additional Resources

### Microsoft Learn Documentation
- [GitHub Copilot in Visual Studio](https://learn.microsoft.com/en-us/visualstudio/ide/visual-studio-github-copilot-install-and-states?view=vs-2022)
- [Visual Studio Azure Integration](https://learn.microsoft.com/en-us/visualstudio/azure/?view=vs-2022)
- [Model Context Protocol](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol)

### GitHub Resources
- [GitHub Copilot Documentation](https://docs.github.com/en/copilot)
- [Model Context Protocol Specification](https://github.com/modelcontextprotocol/specification)
- [MCP SDK and Tools](https://github.com/modelcontextprotocol)

## ‚ùì Troubleshooting

### Common Issues and Solutions

**GitHub Copilot Not Working**:
- Verify GitHub Copilot subscription is active
- Check authentication status in Visual Studio
- Ensure extension is enabled and up to date
- Test with simple code completion scenarios

**MCP Connection Issues**:
- Verify MCP server endpoints are accessible
- Check authentication credentials and permissions
- Validate MCP configuration file syntax
- Monitor network connectivity and firewall settings

**Azure Integration Problems**:
- Verify Azure account has appropriate permissions
- Check Visual Studio Azure workload installation
- Validate Azure service authentication
- Test with simple Azure resource creation

### Getting Help

1. **Review Documentation**: Check Microsoft Learn and GitHub documentation
2. **Check Prerequisites**: Ensure all required tools and subscriptions are active
3. **Test Incrementally**: Start with basic features before advanced integration
4. **Monitor Logs**: Use Visual Studio output windows for debugging
5. **Community Support**: Visit Microsoft Tech Community and GitHub discussions

## üîß Tips for Success

### Best Practices
- **Start Simple**: Begin with basic Copilot features before advanced MCP integration
- **Understand Context**: Learn how AI tools use context for better suggestions
- **Iterate and Refine**: Continuously improve prompts and configurations
- **Security First**: Follow security best practices for AI tool integration
- **Document Configuration**: Keep track of settings and customizations

### Productivity Tips
- **Use Descriptive Comments**: Write clear comments to guide AI suggestions
- **Leverage Templates**: Create reusable code templates with AI assistance
- **Combine Tools**: Use Copilot and MCP together for enhanced capabilities
- **Regular Updates**: Keep tools and extensions updated for best performance
- **Share Knowledge**: Collaborate with team members on AI tool usage
        var timelineMonths = 6;

        // Act
        var result = await _plugin.CreateMigrationPlan(infrastructure, targetRegion, timelineMonths);

        // Assert
        result.Should().NotBeNullOrEmpty();
        result.Should().Contain(infrastructure);
        result.Should().Contain(targetRegion);
        result.Should().Contain(timelineMonths.ToString());
    }

    [Fact]
    public async Task ValidateReadiness_WithMigrationPlan_ReturnsValidationMessage()
    {
        // Arrange
        var migrationPlan = "Migrate to Azure App Service";
        var teamSkills = "Intermediate Azure experience";

        // Act
        var result = await _plugin.ValidateReadiness(migrationPlan, teamSkills);

        // Assert
        result.Should().Contain(migrationPlan);
        result.Should().Contain(teamSkills);
    }

    [Theory]
    [InlineData("", "East US", 6)]
    [InlineData("Infrastructure", "", 6)]
    [InlineData("Infrastructure", "East US", 0)]
    public async Task CreateMigrationPlan_WithInvalidInputs_HandlesGracefully(
        string infrastructure, string targetRegion, int timelineMonths)
    {
        // Act & Assert
        var result = await _plugin.CreateMigrationPlan(infrastructure, targetRegion, timelineMonths);
        result.Should().NotBeNull(); // Should handle invalid inputs gracefully
    }
}
```

**4.1.2 Create Integration Tests for MCP Server (15 minutes)**

**MCP Integration Tests**:
1. Create `MCPServerIntegrationTests.cs`:
```csharp
using Microsoft.Azure.Functions.Worker;
using Microsoft.Azure.Functions.Worker.Http;
using Microsoft.Extensions.Logging;
using Xunit;
using FluentAssertions;
using System.Text.Json;

public class MCPServerIntegrationTests : IClassFixture<TestServerFixture>
{
    private readonly TestServerFixture _fixture;

    public MCPServerIntegrationTests(TestServerFixture fixture)
    {
        _fixture = fixture;
    }

    [Fact]
    public async Task ListResources_WithValidRequest_ReturnsResourceList()
    {
        // Arrange
        var request = new MCPListResourcesRequest 
        { 
            SubscriptionId = "test-subscription-id" 
        };

        // Act
        var response = await _fixture.Client.PostAsync("/api/mcp-list-resources", 
            new StringContent(JsonSerializer.Serialize(request)));

        // Assert
        response.IsSuccessStatusCode.Should().BeTrue();
        var content = await response.Content.ReadAsStringAsync();
        content.Should().Contain("resource_list");
    }

    [Fact]
    public async Task AssessMigration_WithResourceId_ReturnsAssessment()
    {
        // Arrange
        var request = new MCPAssessmentRequest 
        { 
            ResourceId = "/subscriptions/test/resourceGroups/test/providers/Microsoft.Compute/virtualMachines/testvm",
            ResourceType = "Microsoft.Compute/virtualMachines"
        };

        // Act
        var response = await _fixture.Client.PostAsync("/api/mcp-assess-migration", 
            new StringContent(JsonSerializer.Serialize(request)));

        // Assert
        response.IsSuccessStatusCode.Should().BeTrue();
        var content = await response.Content.ReadAsStringAsync();
        var assessment = JsonSerializer.Deserialize<dynamic>(content);
        assessment.Should().NotBeNull();
    }
}
```

**4.1.3 Create End-to-End Workflow Tests (10 minutes)**

**E2E Test Implementation**:
1. Create `EndToEndWorkflowTests.cs`:
```csharp
public class EndToEndWorkflowTests
{
    [Fact]
    public async Task CompleteE2EMigrationWorkflow_ExecutesSuccessfully()
    {
        // Arrange - Set up test scenario
        var infrastructure = "Test infrastructure with 3 VMs";
        var targetRegion = "East US 2";
        var timeline = 3;

        // Act - Execute complete workflow
        // 1. SK analyzes infrastructure
        var kernel = CreateTestKernel();
        var analysisResult = await kernel.InvokePromptAsync(
            "Analyze infrastructure: {{$infrastructure}}", 
            new KernelArguments { ["infrastructure"] = infrastructure });

        // 2. MCP server provides resource data
        var mcpClient = new TestMCPClient();
        var resources = await mcpClient.ListResourcesAsync();

        // 3. Generate migration plan
        var planResult = await kernel.InvokePromptAsync(
            "Create migration plan based on: {{$analysis}} and {{$resources}}",
            new KernelArguments 
            { 
                ["analysis"] = analysisResult.ToString(),
                ["resources"] = JsonSerializer.Serialize(resources)
            });

        // Assert
        analysisResult.Should().NotBeNull();
        resources.Should().NotBeEmpty();
        planResult.ToString().Should().Contain("migration");
    }
}
```

### Challenge 4.2: Production Monitoring & Observability (40 minutes)
**Goal**: Implement comprehensive monitoring for AI systems in production

#### Step-by-Step Implementation:

**4.2.1 Application Insights Integration (20 minutes)**

**Add Monitoring to SK Application**:
1. Add Application Insights to your SK project:
```bash
dotnet add package Microsoft.ApplicationInsights
dotnet add package Microsoft.ApplicationInsights.AspNetCore
```

2. Update `Program.cs` with monitoring:
```csharp
using Microsoft.ApplicationInsights;
using Microsoft.ApplicationInsights.Extensibility;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.Logging;

var builder = Host.CreateDefaultBuilder(args);

builder.ConfigureServices(services =>
{
    // Add Application Insights
    services.AddApplicationInsightsTelemetry();
    
    // Add Semantic Kernel with monitoring
    services.AddTransient<Kernel>(provider =>
    {
        var kernelBuilder = Kernel.CreateBuilder();
        kernelBuilder.AddAzureOpenAIChatCompletion(
            deploymentName: "gpt-4-migration-agent",
            endpoint: "YOUR_ENDPOINT",
            credential: new DefaultAzureCredential()
        );
        
        var kernel = kernelBuilder.Build();
        
        // Add telemetry to kernel
        var telemetryClient = provider.GetService<TelemetryClient>();
        kernel.FunctionInvoking += (sender, e) =>
        {
            telemetryClient?.TrackEvent("SKFunctionInvoking", new Dictionary<string, string>
            {
                ["FunctionName"] = e.Function.Name,
                ["PluginName"] = e.Function.PluginName
            });
        };
        
        return kernel;
    });
});

var host = builder.Build();

// Custom metrics tracking
var telemetryClient = host.Services.GetService<TelemetryClient>();

// Track migration workflow execution
telemetryClient?.TrackEvent("MigrationWorkflowStarted");

// Your existing SK code here...

telemetryClient?.TrackEvent("MigrationWorkflowCompleted");
await host.RunAsync();
```

**4.2.2 Custom Metrics and Dashboards (20 minutes)**

**Create Custom Metrics**:
1. Add custom telemetry tracking:
```csharp
public class MigrationTelemetryService
{
    private readonly TelemetryClient _telemetryClient;

    public MigrationTelemetryService(TelemetryClient telemetryClient)
    {
        _telemetryClient = telemetryClient;
    }

    public void TrackMigrationAssessment(string resourceType, double assessmentTime, bool successful)
    {
        _telemetryClient.TrackEvent("MigrationAssessment", new Dictionary<string, string>
        {
            ["ResourceType"] = resourceType,
            ["Successful"] = successful.ToString()
        }, new Dictionary<string, double>
        {
            ["AssessmentTimeMs"] = assessmentTime
        });
    }

    public void TrackAITokenUsage(string model, int tokenCount, double cost)
    {
        _telemetryClient.TrackMetric("AITokenUsage", tokenCount, new Dictionary<string, string>
        {
            ["Model"] = model
        });
        
        _telemetryClient.TrackMetric("AICost", cost, new Dictionary<string, string>
        {
            ["Model"] = model
        });
    }

    public void TrackMigrationPlanGeneration(int resourceCount, double planningTime, string complexity)
    {
        _telemetryClient.TrackEvent("MigrationPlanGenerated", new Dictionary<string, string>
        {
            ["Complexity"] = complexity
        }, new Dictionary<string, double>
        {
            ["ResourceCount"] = resourceCount,
            ["PlanningTimeSeconds"] = planningTime
        });
    }
}
```

### Challenge 4.3: CI/CD and Production Deployment (30 minutes)
**Goal**: Create automated deployment pipeline for AI migration system

#### Step-by-Step Implementation:

**4.3.1 GitHub Actions Workflow (20 minutes)**

**Create Deployment Pipeline**:
1. Create `.github/workflows/deploy-migration-system.yml`:
```yaml
name: Deploy AI Migration System

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup .NET
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: '8.0.x'
    
    - name: Restore dependencies
      run: dotnet restore
    
    - name: Build
      run: dotnet build --no-restore
    
    - name: Run Unit Tests
      run: dotnet test --no-build --verbosity normal --collect:"XPlat Code Coverage"
    
    - name: Run Integration Tests
      run: dotnet test --no-build --verbosity normal --filter Category=Integration

  deploy-functions:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Setup .NET
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: '8.0.x'
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Deploy Azure Functions
      run: |
        cd MCPMigrationServer
        func azure functionapp publish mcp-migration-server-prod
```

**4.3.2 Production Configuration (10 minutes)**

**Environment-Specific Settings**:
1. Create `appsettings.Production.json`:
```json
{
  "AzureOpenAI": {
    "Endpoint": "https://your-production-openai.openai.azure.com/",
    "DeploymentName": "gpt-4-migration-prod"
  },
  "ApplicationInsights": {
    "InstrumentationKey": "your-production-app-insights-key"
  },
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft": "Warning"
    }
  }
}
```

2. Configure production monitoring alerts:
   - High error rates (>5%)
   - Slow response times (>30 seconds)
   - High AI token usage costs
   - Failed migration assessments

**4.1.2 Configure Azure Monitor Alerts via Portal (25 minutes)**

**Create Resource Health Alert**:
1. Azure Portal ‚Üí "Monitor" ‚Üí "Alerts"
2. Click "Create" ‚Üí "Alert rule"
3. Configure scope:
   - **Resource**: Select your migration resources
   - **Condition**: Resource health
4. Set condition:
   - **Signal type**: Resource health
   - **Alert logic**: Current health status equals Unavailable
5. Configure action group:
   - **Action group name**: migration-alerts
   - **Action**: Email notification to your email
6. Set alert rule details:
   - **Alert rule name**: Migration Resource Health Alert
   - **Severity**: Critical (Sev 0)
7. Click "Create alert rule"

**Create Performance Alert**:
1. Create another alert rule
2. Configure:
   - **Resource**: Application Insights resource
   - **Condition**: Server response time
   - **Threshold**: Greater than 5 seconds
   - **Evaluation frequency**: Every 1 minute
   - **Action**: Use the same action group

**Create Cost Alert**:
1. Go to "Cost Management + Billing"
2. Navigate to "Cost alerts"
3. Click "Add" ‚Üí "Budget alert"
4. Configure:
   - **Budget scope**: Resource group (rg-migration-ai-portal)
   - **Budget amount**: $100 (or appropriate amount)
   - **Alert conditions**: 80% and 100% of budget
   - **Alert recipients**: Your email

**4.1.3 Set Up Log Analytics Workspace (15 minutes)**

**Configure Data Collection**:
1. Go to your Log Analytics Workspace
2. Navigate to "Agents" ‚Üí "Data collection rules"
3. Click "Create" to set up data collection
4. Configure:
   - **Rule name**: migration-data-collection
   - **Resource group**: rg-migration-ai-portal
   - **Resources**: Add your VMs and resources

**Create Custom Queries**:
1. Go to "Logs" in your workspace
2. Create useful queries for migration monitoring:

**Migration Progress Query**:
```kql
AzureActivity
| where OperationName contains "migration" or OperationName contains "deploy"
| summarize count() by OperationName, bin(TimeGenerated, 1h)
| render timechart
```

**Error Analysis Query**:
```kql
AppExceptions
| where TimeGenerated > ago(24h)
| summarize count() by Type, bin(TimeGenerated, 1h)
| render barchart
```

**Performance Trends Query**:
```kql
AppRequests
| where TimeGenerated > ago(7d)
| summarize avg(DurationMs) by bin(TimeGenerated, 1h)
| render timechart
```

**Save Queries**:
1. Click "Save" for each query
2. Add to dashboard
3. Set up as alert queries if needed

**4.1.4 Configure Workbooks for Advanced Analytics (15 minutes)**

**Create Migration Workbook**:
1. Go to Application Insights ‚Üí "Workbooks"
2. Click "New" ‚Üí "Empty Workbook"
3. Add sections:

**Overview Section**:
- Add text: "Migration Status Overview"
- Add metrics: Total requests, error rate, response time
- Add time range selector

**Performance Analysis**:
- Add query visualization for response times
- Add dependency map
- Add failure analysis charts

**Resource Utilization**:
- Add CPU and memory usage charts
- Add network and disk I/O metrics
- Add auto-scaling recommendations

**Save and Share**:
1. Click "Save As"
2. Name: "Migration Monitoring Workbook"
3. Share with team members via "Share" button

**üí° Portal Tips**:
- Use Azure Mobile App for monitoring on-the-go
- Set up Teams notifications for critical alerts
- Create separate dashboards for different stakeholders
- Use resource tags for better organization and cost tracking

### Challenge 4.2: AI Governance and Compliance (60 minutes)
**Goal**: Implement comprehensive AI governance and responsible AI practices

**Tasks**:
1. Build AI model monitoring and governance:
   - Model performance tracking and drift detection
   - Bias detection and fairness monitoring across AI decisions
   - Explainability frameworks for AI recommendations
   - Version control and rollback capabilities for AI models
2. Implement responsible AI safeguards:
   - Content safety and filtering for AI interactions
   - Prompt injection detection and prevention mechanisms
   - Output validation and quality assurance frameworks
   - Human-in-the-loop approval workflows for critical decisions
3. Create compliance and audit frameworks:
   - Automated compliance checking against regulatory requirements
   - Audit trail generation for all AI decisions and actions
   - Privacy protection and data handling compliance
   - Regular AI ethics and bias assessment reporting
4. Add transparency and explainability features:
   - Natural language explanations for AI decisions
   - Visual representation of AI reasoning processes
   - Confidence scoring and uncertainty quantification
   - Alternative recommendation exploration and comparison

**Verification**: AI systems operate with full transparency, compliance, and responsible governance

### Challenge 4.3: Intelligent Cost Optimization (60 minutes)
**Goal**: Create AI-driven cost management and optimization systems

**Tasks**:
1. Implement AI-powered cost analysis:
   - Predictive cost modeling based on usage patterns
   - AI-driven cost anomaly detection and alerting
   - Intelligent resource utilization analysis and optimization
   - Multi-cloud cost comparison and optimization recommendations
2. Build intelligent resource optimization:
   - AI-powered resource right-sizing based on performance analysis
   - Predictive scaling based on workload forecasting
   - Intelligent workload scheduling for cost optimization
   - Dynamic resource allocation with cost-performance trade-offs
3. Create cost intelligence dashboards:
   - AI-generated cost insights and trend analysis
   - Predictive budget impact assessment and warnings
   - Intelligent cost allocation and chargeback automation
   - ROI analysis and optimization recommendations
4. Add automated cost optimization actions:
   - Intelligent auto-scaling with cost awareness
   - Automated resource cleanup and optimization
   - Smart scheduling of non-critical workloads
   - AI-driven commitment and reservation recommendations

**Verification**: System automatically optimizes costs while maintaining performance requirements

### Challenge 4.4: Production Deployment & Scaling (75 minutes)
**Goal**: Deploy AI-powered migration system with enterprise-grade reliability

**Tasks**:
1. Implement AI-enhanced deployment strategies:
   - Intelligent blue-green deployment with AI-powered validation
   - Canary releases with AI monitoring and automatic rollback
   - Feature flag management with AI-driven gradual rollout
   - AI-powered deployment risk assessment and mitigation
2. Build intelligent scaling and load management:
   - AI-driven predictive auto-scaling based on workload patterns
   - Intelligent load balancing with performance optimization
   - Smart resource allocation across multiple regions
   - AI-enhanced disaster recovery and failover strategies
3. Create production monitoring and alerting:
   - AI-powered SLA monitoring with predictive breach detection
   - Intelligent incident response and escalation automation
   - Real-time performance optimization recommendations
   - Automated capacity planning and resource provisioning
4. Add continuous improvement mechanisms:
   - AI-powered performance analysis and optimization suggestions
   - Automated A/B testing for AI model improvements
   - Continuous learning from production patterns and feedback
   - Intelligent system evolution and adaptation recommendations

**Verification**: Production system scales intelligently and maintains high availability

### Challenge 4.5: AI Performance Optimization (45 minutes)
**Goal**: Optimize AI system performance for production workloads

**Tasks**:
1. Implement AI model optimization:
   - Model compression and quantization for faster inference
   - Intelligent caching strategies for AI responses
   - Batch processing optimization for high-throughput scenarios
   - AI model ensembling and performance optimization
2. Build intelligent request routing and load balancing:
   - AI-powered request routing based on complexity and requirements
   - Dynamic load balancing across multiple AI service instances
   - Intelligent failover and redundancy management
   - Smart rate limiting and throttling strategies
3. Create performance monitoring and optimization:
   - Real-time AI performance metrics and analysis
   - Intelligent bottleneck detection and resolution
   - AI-driven optimization recommendations and automation
   - Continuous performance tuning and improvement
4. Add advanced optimization techniques:
   - Intelligent prompt optimization for better AI responses
   - Dynamic model selection based on request characteristics
   - AI-powered resource allocation and scaling decisions
   - Predictive performance analysis and optimization planning

**Verification**: AI systems deliver optimal performance under production load conditions

## üìù Deliverables

- [ ] AI-enhanced monitoring and observability platform
- [ ] Comprehensive AI governance and compliance framework
- [ ] Intelligent cost optimization and management system
- [ ] Production-ready deployment with intelligent scaling
- [ ] AI performance optimization and monitoring

## üîß Instructor Resources

### Advanced AI Operations Teaching Guide

#### AI Monitoring and Observability Best Practices
**Key Teaching Points**:
- **Telemetry Strategy**: What to monitor in AI systems vs traditional applications
- **Anomaly Detection**: Different types of anomalies in AI systems
- **Model Monitoring**: Drift detection, performance degradation, bias monitoring
- **Explainability**: Making AI decisions transparent and auditable

#### Responsible AI in Production
**Critical Concepts**:
- **AI Ethics**: Fairness, transparency, accountability, privacy
- **Safety Mechanisms**: Content filtering, output validation, human oversight
- **Compliance**: GDPR, industry-specific regulations, audit requirements
- **Risk Management**: Identifying and mitigating AI-specific risks

#### Production AI Architecture Patterns
**Architecture Considerations**:
- **Scalability**: Handling variable AI workloads and request patterns
- **Reliability**: Ensuring AI system availability and fault tolerance
- **Performance**: Optimizing AI inference and response times
- **Cost Management**: Balancing AI capability with operational costs

### Demonstration Scenarios
1. **AI Anomaly Detection**: Live demo of AI detecting unusual patterns
2. **Cost Optimization**: Show AI-driven cost reduction in action
3. **Responsible AI**: Demonstrate bias detection and explainability
4. **Production Scaling**: Show intelligent auto-scaling under load

### Advanced Troubleshooting Guide
- **AI Model Performance Issues**: Debugging slow or inaccurate AI responses
- **Monitoring Data Overload**: Managing high-volume telemetry effectively
- **Cost Spike Investigation**: Using AI to identify unexpected cost increases
- **Compliance Violations**: Detecting and resolving AI governance issues

## üöÄ Final Project Achievement

After completing Day 4 challenges, participants will have built a complete, production-ready AI-powered migration automation system with:
- Intelligent planning and execution capabilities
- Advanced monitoring and observability
- Responsible AI governance and compliance
- Cost optimization and performance management
- Enterprise-grade reliability and scalability

## üìö Additional Resources

- [Azure AI Monitoring Best Practices](https://docs.microsoft.com/en-us/azure/ai-services/monitoring)
- [Responsible AI Framework](https://www.microsoft.com/en-us/ai/responsible-ai)
- [Azure Cost Management + Billing](https://docs.microsoft.com/en-us/azure/cost-management-billing/)
- [Azure Well-Architected Framework](https://docs.microsoft.com/en-us/azure/architecture/framework/)

## ‚ùì Troubleshooting

**Common Production Issues**:
- **AI Model Drift**: Performance degradation over time
- **Cost Optimization Conflicts**: Balancing performance vs cost
- **Monitoring Overload**: Too much data without actionable insights
- **Compliance Gaps**: Missing audit trails or governance controls
